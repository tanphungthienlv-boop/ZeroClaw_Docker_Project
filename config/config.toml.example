# ZeroClaw Configuration (TOML)
# Auto-generated by entrypoint.sh

default_provider = "custom:https://generativelanguage.googleapis.com/v1beta/openai"
default_model = "gemini-2.0-flash"
default_temperature = 0.7

[memory]
backend = "sqlite"
auto_save = true

[gateway]
require_pairing = false
allow_public_bind = true

[channels_config]
cli = true

[channels_config.telegram]
bot_token = "YOUR_TELEGRAM_BOT_TOKEN_HERE"
allowed_users = ["*"]

# Fallback model chain: thử lần lượt nếu model trước thất bại
[[model_routes]]
hint = "flash"
provider = "custom:https://generativelanguage.googleapis.com/v1beta/openai"
model = "gemini-2.0-flash"

[[model_routes]]
hint = "flash-lite"
provider = "custom:https://generativelanguage.googleapis.com/v1beta/openai"
model = "gemini-2.0-flash-lite"

[[model_routes]]
hint = "flash-15"
provider = "custom:https://generativelanguage.googleapis.com/v1beta/openai"
model = "gemini-1.5-flash"

[[model_routes]]
hint = "pro"
provider = "custom:https://generativelanguage.googleapis.com/v1beta/openai"
model = "gemini-1.5-pro"

[secrets]
encrypt = false
